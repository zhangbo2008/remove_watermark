import aiohttp
import asyncio
import json
import os
from notify import send
from bs4 import BeautifulSoup

def load_cookies():
    global amazon_cookies
    cookie_file = "amazon_cookies.json"
    with open(cookie_file, "r") as f:
        amazon_cookies = json.loads(f.read())

def get_urls():
    urls_str = os.getenv('amazon_urls', '')
    
    # ä½¿ç”¨æ¢è¡Œç¬¦åˆ†å‰² URL
    urls = [url.strip() for url in urls_str.split('\n') if url.strip()]
    return urls

async def fetch_amazon_product(url):
    headers = {
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "accept-language": "en-US,en;q=0.9",
        "cache-control": "max-age=0",
        "device-memory": "4",
        "downlink": "10",
        "dpr": "1",
        "ect": "4g",
        "priority": "u=0, i",
        "rtt": "50",
        "sec-ch-device-memory": "4",
        "sec-ch-dpr": "1",
        "sec-ch-ua": '"Chromium";v="129", "Not=A?Brand";v="8"',
        "sec-ch-ua-mobile": "?1",
        "sec-ch-ua-platform": '"Android"',
        "sec-ch-ua-platform-version": '"6.0"',
        "sec-ch-viewport-width": "400",
        "sec-fetch-dest": "document",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "none",
        "sec-fetch-user": "?1",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Mobile Safari/537.36",
        "viewport-width": "400"
    }

    proxy = os.getenv('http_proxy')
        
    # ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(
                    url,
                    headers=headers, 
                    cookies=amazon_cookies,                    
                    proxy=proxy) as response: # ä½¿ç”¨ä»£ç†
                if response.status == 200:
                    return await response.text()
                else:
                    print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}")
                    return None
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            return None
        
        
async def main():
    urls = get_urls()
    load_cookies()
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for url in urls:
        task = asyncio.create_task(fetch_amazon_product(url))
        tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œ
    for task in asyncio.as_completed(tasks):
        try:
            result = await task
            if result:
                print("è¯·æ±‚æˆåŠŸï¼")
                soup = BeautifulSoup(result, 'html.parser')
                add_to_cart_element = soup.find('input', {'id': 'add-to-cart-button'})

                if add_to_cart_element:
                    product_title = soup.find('meta', attrs={'name': 'title'})['content']
                    send(
                        title='ğŸ¯ Amazon å‘ç°ç›®æ ‡å•†å“ï¼',
                        content=f'''## {product_title}

> **ç›´è¾¾é“¾æ¥ï¼š**
> [ç‚¹å‡»è´­ä¹°]({url})

---
åŸå§‹é“¾æ¥ï¼š{url}'''
                    )
                    print("å·²å‘é€åº“å­˜é€šçŸ¥")
                else:
                    print("å•†å“æš‚æ— åº“å­˜")
        except Exception as e:
            print(f"æ£€æŸ¥åº“å­˜æ—¶å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())














